# -*- coding: utf-8 -*-
"""ADVANCED GAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sJAs6I41z9AmD3Hd0ExMzjHLxfo92UPZ
"""

#Importing libraries
import torch, torchvision, os , PIL, pdb
from torch import nn
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.utils import make_grid
from tqdm.auto import tqdm
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def show (tensor, num=25, wandbactive =0, name=''): #burada bir değişim olabilir
  data = tensor.detach().cpu()
  grid = make_grid(data[:num], nrow=5).permute(1,2,0)

  ## optional
  if (wandbactive==1 ): #and wandbact == 1
    wandb.log({name:wandb.Image(grid.numpy().clip(0,1))})


  plt.imshow(grid.clip(0,1))
  plt.show()


### hyperparameters and general parameters
n_epochs =20
batch_size=32
lr=1e-4
z_dim=200
device='cpu' #gpu

cur_step=0
crit_cycles=5
gen_losses=[]
crit_losses=[]
show_step=35
save_step=35

wandbact=1 #yes,we want to track stats through weights and biases, optional

### optional
!pip install wandb -qqq
import wandb
wandb.login(key = 'de5c2b1a325ea05f63b9be1dd1ae35429ad1dcd8')

#%%capture
experiment_name= wandb.util.generate_id()


myrun=wandb.init(
    project='wgan',
    group=experiment_name,
    config={
        "optimizer": "adam",
        "model":"wgan gp",
        "epoch":"20",
        "batch_size":32
    }
)
config=wandb.config

print(experiment_name)

class Generator(nn.Module):
  def __init__(self, z_dim=64, d_dim=16):
    super(Generator, self).__init__()
    self.z_dim=z_dim

    self.gen =nn.Sequential(
        ##ConvTranspose2d: in_channels, out_channels, kernel_size, stride=1, padding=0
        ##Xalculating new width and height: (n-1)*stride -2*padding +ks
        ##n=width or height
        #ks= kernel size
        ##we begin with a 1x1 image with z_dim number of channels(200)
        nn.ConvTranspose2d(z_dim, d_dim*32, 4, 1, 0),## 4x4 (ch:200,512)
        nn.BatchNorm2d(d_dim*32),
        nn.ReLU(True),

        nn.ConvTranspose2d(d_dim*32, d_dim*16, 4, 2, 1),##8x8(ch:512,256)
        nn.BatchNorm2d(d_dim*16),
        nn.ReLU(True),

        nn.ConvTranspose2d(d_dim*16, d_dim*8, 4, 2, 1),##16x16(ch:256,128)
        #(n-1)*stride -2*padding +ks= (8-1)*2-2*1+4=16
        nn.BatchNorm2d(d_dim*8),
        nn.ReLU(True),

        nn.ConvTranspose2d(d_dim*8, d_dim*4, 4, 2, 1),##32x32(ch:128,64)
        nn.BatchNorm2d(d_dim*4),
        nn.ReLU(True),

        nn.ConvTranspose2d(d_dim*4, d_dim*2, 4, 2, 1),##64x64(ch:64,32)
        nn.BatchNorm2d(d_dim*2),
        nn.ReLU(True),

        nn.ConvTranspose2d(d_dim*2, 3, 4, 2, 1),##128x128(ch:32,3)
        nn.Tanh()##PRODUCe result in the range from -1 to 1

    )

  def forward(self, noise):
    x=noise.view(len(noise), self.z_dim, 1,1)##18x20x1x1
    return self.gen(x)


def gen_noise(num, z_dim, device='cpu'):
  return torch.randn(num, z_dim, device=device)#128x200

##critic model


class Critic(nn.Module):
  def __init__(self, d_dim=16):
    super(Critic, self).__init__()

    self.crit=nn.Sequential(
    #nn.ConvTranspose2d: (n-1)*stride -2*padding +ks
    #nn.Conv2d:(n+2*pad-ks)//stride +1
    nn.Conv2d(3, d_dim, 4, 2, 1),##(n+2*pad-ks)//stride +1 (128+2*1-4)//2+1=64x64 (ch:3,16)
    nn.InstanceNorm2d(d_dim),
    nn.LeakyReLU(0.2),

    nn.Conv2d(d_dim, d_dim*2, 4, 2, 1),##32X32 (ch: 16,32)
    nn.InstanceNorm2d(d_dim*2),
    nn.LeakyReLU(0.2),

    nn.Conv2d(d_dim*2, d_dim*4, 4, 2, 1),##16x16 (ch: 32,64)
    nn.InstanceNorm2d(d_dim*4),
    nn.LeakyReLU(0.2),

    nn.Conv2d(d_dim*4, d_dim*8, 4, 2, 1),##8x8 (ch: 64,128)
    nn.InstanceNorm2d(d_dim*8),
    nn.LeakyReLU(0.2),

    nn.Conv2d(d_dim*8, d_dim*16, 4, 2, 1),##4x4 (ch: 128,256)
    nn.InstanceNorm2d(d_dim*16),
    nn.LeakyReLU(0.2),

    nn.Conv2d(d_dim*16, 1, 4, 1, 0),##(n+2*pad-ks)//stride +1 =(4+2*0-4)//1+1=1x1 (ch:256,1)
    )
  def forward(self,image):
    #image: 128x3x128x128
    crit_pred=self.crit(image)#128x1x1x1x
    return crit_pred.view(len(crit_pred), -1)##128x1

##optional , init your weights in different ways
def init_weights(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):
        torch.nn.init.normal_(m.weight, 0.0, 0.02)
        torch.nn.init.constant_(m.bias, 0)

    if isinstance(m, nn.BatchNorm2d):
        torch.nn.init.normal_(m.weight, 0.0, 0.02)
        torch.nn.init.constant_(m.bias, 0)

    ##gen=gen.apply(init_weights)
    ##crit=crit.apply(init_weights)

#load dataset
import gdown  #https://drive.google.com/drive/folders/1-2UumHVKrSSe3Sg8m0jJFaNqfcHv_TLN?usp=drive_link
import zipfile
import os
url= 'https://dl.dropboxusercontent.com/scl/fi/vltmt8hlgdf9mv9kn7d0b/img_align_celeba.zip?rlkey=tacwpkr8d9bjpctdftjg3b00a'
path='data/celeba'
download_path=f'{path}/img_align_celeba.zip'

if not os.path.exists(path):
  os.makedirs(path)

gdown.download(url, download_path, quiet=False)

with zipfile.ZipFile(download_path, 'r') as ziphandler:
    ziphandler.extractall(path)

!pip install intel-extension-for-pytorch[xpu]

##Düzelttim bu kısmı artık çalışıyor
### Dataset , DataLoader, declare gen , crit, test dataset
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
from torch.utils.data import Dataset, DataLoader

class MyDataset(Dataset):
   def __init__(self, path, size=128, lim=5000):#10000 idi 100 yapıtm
      self.sizes=[size, size]
      items,labels=[],[]


      for data in os.listdir(path)[:lim]:
       # path: './content/data/celeba/img_align_celeba.zip'
        #data: '114568.jpg'
        item = os.path.join(path,data)
        items.append(item)
        labels.append(data)

      self.items=items
      self.labels=labels


   def __len__(self):
      return len(self.items)

   def __getitem__(self, idx):
      data = PIL.Image.open(self.items[idx]).convert('RGB') #(178,218)
      data =  np.asarray(torchvision.transforms.Resize(self.sizes)(data))##128x128x3
      data =  np.transpose(data, (2,0,1)).astype(np.float32, copy=False)# 3x128x128 # froem 0 to 255
      data =  torch.from_numpy(data).div(255)#from 0 to 1
      return data, self.labels[idx]

      ##Dataset

data_path = './data/celeba/img_align_celeba'
ds = MyDataset(data_path, size= 128,  lim=5000)#10000 idi 100 yaptım


    ##DataLoader
dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True)

    ##Models
gen = Generator(z_dim).to(device)
crit = Critic().to(device)

    ##Optimizers
gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.9))
crit_opt = torch.optim.Adam(crit.parameters(), lr=lr, betas=(0.5, 0.9))

    ##Loss
#crit_loss = nn.BCEWithLogitsLoss()

  ##Initializations
  ##gen=gen.apply(init_weights)
  ##crit=crit.apply(init_weights)

  #wandb optional
if (wandbact==1):
    wandb.watch(gen, log_freq= 100)
    wandb.watch(crit, log_freq= 100)


x,y = next(iter(dataloader))
show(x)

## gradient penalty calculation

def get_gp(real, fake, crit, alpha, gamma=10):
  mix_images = real * alpha + fake * (1 - alpha) #128x3x128x128
  mix_scores = crit(mix_images)

  gradient = torch.autograd.grad(
      inputs = mix_images,
      outputs = mix_scores,
      grad_outputs=torch.ones_like(mix_scores),#.to(device)
      retain_graph=True,
      create_graph=True,
  )[0]

  gradient = gradient.view(len(gradient), -1)
  gradient_norm = gradient.norm(2, dim=1)
  gp = gamma * ((gradient_norm-1)**2).mean()

  return gp

## Save and load checkpoints
root_path= './data/'

def save_checkpoint(name):
  torch.save({
      'epoch': epoch,
      'model_state_dict': gen.state_dict(),
      'optimizer_state_dict': gen_opt.state_dict(),

  }, f"{root_path}G-{name}.pkl")
  torch.save({
      'epoch': epoch,
      'model_state_dict': crit.state_dict(),
      'optimizer_state_dict': crit_opt.state_dict(),

  }, f"{root_path}C-{name}.pkl")

  print("Saved checkpoint")

def load_checkpoint(name):
  checkpoint = torch.load(f"{root_path}G-{name}.pkl")
  gen.load_state_dict(checkpoint['model_state_dict'])
  gen_opt.load_state_dict(checkpoint['optimizer_state_dict'])

  checkpoint = torch.load(f"{root_path}C-{name}.pkl")
  crit.load_state_dict(checkpoint['model_state_dict'])
  crit_opt.load_state_dict(checkpoint['optimizer_state_dict'])

  print("Loaded checkpoint")

epoch = 1
save_checkpoint("test")

load_checkpoint("test")

#training loop

for epoch in range(n_epochs):
 for real, _ in tqdm(dataloader):
    cur_bs = len(real)
    real = real.to(device)

    ###CRITIC
    mean_crit_loss = 0
    for _ in range(crit_cycles):
      crit_opt.zero_grad()

      noise = gen_noise(cur_bs, z_dim)
      fake = gen(noise)
      crit_fake_pred = crit(fake.detach())
      crit_real_pred = crit(real)

      alpha = torch.rand(len(real),1,1,1,device = device, requires_grad=True) #128x1x1x1
      gp = get_gp(real, fake.detach(), crit, alpha)

      crit_loss = crit_fake_pred.mean() - crit_real_pred.mean() + gp
      mean_crit_loss+= crit_loss.item() / crit_cycles
      crit_loss.backward(retain_graph=True)
      crit_opt.step()

    crit_losses += [mean_crit_loss]

   ###GENERATOR
    gen_opt.zero_grad()
    noise = gen_noise(cur_bs, z_dim)
    fake = gen(noise)
    crit_fake_pred = crit(fake)

    gen_loss = -crit_fake_pred.mean()
    gen_loss.backward()
    gen_opt.step()

    gen_losses += [gen_loss.item()]

 ## STATS
#if (wandbact==1):
    wandb.log({"Epoch": epoch, 'Step': cur_step, 'Critic Loss': mean_crit_loss, 'Gen Loss': gen_loss})

if cur_step % save_step == 0  and cur_step >0:
    print("Saving checkpoint: ", cur_step, save_step)
    save_checkpoint("latest")

##if (cur_step % show_step == 0 and cur_step>0):
 ##    show(fake, wandbactive = 1, name= 'fake')
   ##  show(real, wandbactive = 1, name='real')
if (cur_step % show_step == 0 and cur_step > 0):
            # Görselleri WandB'ye logla
      fake = fake[:8].detach().cpu()  # İlk 8 sahte görüntü
      real = real[:8].detach().cpu()  # İlk 8 gerçek görüntü

      wandb.log({
           "Fake Images": [wandb.Image(img, caption=f"Fake Image {i}") for i, img in enumerate(fake)],
            "Real Images": [wandb.Image(img, caption=f"Real Image {i}") for i, img in enumerate(real)]
            })
      gen_mean=sum(gen_losses[-show_step:]) / show_step
      crit_mean=sum(crit_losses[-show_step:]) / show_step
      print(f"Epoch: {epoch}: Step {cur_step}: Generator Loss: {gen_mean}, critic loss: {crit_mean} ")

      plt.plot(
          range(len(gen_losses)),
          torch.Tensor(gen_losses),
          label = "Generator Loss"
      )
      plt.plot(
          range(len(gen_losses)),
          torch.Tensor(crit_losses),
          label="Critic Loss"
      )

for epoch in range(n_epochs):
    for real, _ in tqdm(dataloader):
        cur_bs = len(real)
        real = real.to(device)

        ### CRITIC UPDATE
        mean_crit_loss = 0
        for _ in range(crit_cycles):
            crit_opt.zero_grad()

            noise = gen_noise(cur_bs, z_dim)
            fake = gen(noise)
            crit_fake_pred = crit(fake.detach())
            crit_real_pred = crit(real)

            alpha = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)
            gp = get_gp(real, fake.detach(), crit, alpha)

            crit_loss = crit_fake_pred.mean() - crit_real_pred.mean() + gp
            mean_crit_loss += crit_loss.item() / crit_cycles
            crit_loss.backward(retain_graph=True)
            crit_opt.step()

        crit_losses.append(mean_crit_loss)

        ### GENERATOR UPDATE
        gen_opt.zero_grad()
        noise = gen_noise(cur_bs, z_dim)
        fake = gen(noise)
        crit_fake_pred = crit(fake)

        gen_loss = -crit_fake_pred.mean()
        gen_loss.backward()
        gen_opt.step()

        gen_losses.append(gen_loss.item())

        ### LOGGING
        cur_step += 1
        if cur_step % save_step == 0:
            print("Saving checkpoint...")
            save_checkpoint("latest")

        if cur_step % show_step == 0:
            fake = fake[:8].detach().cpu().permute(0, 2, 3, 1).clip(0, 1)
            real = real[:8].detach().cpu().permute(0, 2, 3, 1).clip(0, 1)

            wandb.log({
                "Fake Images": [wandb.Image(img.numpy(), caption=f"Fake Image {i}") for i, img in enumerate(fake)],
                "Real Images": [wandb.Image(img.numpy(), caption=f"Real Image {i}") for i, img in enumerate(real)],
                "Critic Loss": mean_crit_loss,
                "Generator Loss": gen_loss.item()
            })

            print(f"Epoch: {epoch}, Step: {cur_step}, Generator Loss: {gen_loss.item()}, Critic Loss: {mean_crit_loss}")